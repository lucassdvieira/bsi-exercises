{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from bs4 import BeautifulSoup\n",
        "import string\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-10yxePERhy2",
        "outputId": "9aaf067d-a7de-49e0-88bd-ed0d512cfd03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\"\n",
        "<!DOCTYPE html>\n",
        "<html>\n",
        "<head>\n",
        "    <title>Example Title</title>\n",
        "</head>\n",
        "<body>\n",
        "    <p>This is an example paragraph. It contains some text! Text preprocessing is crucial for natural language processing (NLP).</p>\n",
        "    <p>Considerations for cleaning text data include removing HTML tags, punctuation, and stop words. Additionally, you might perform stemming and lemmatization.</p>\n",
        "</body>\n",
        "</html>\n",
        "\"\"\"\n",
        "\n",
        "print(\"Texto Inicial:\")\n",
        "print(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w_rLDkzmRkEB",
        "outputId": "82c9b2d9-4bf0-4bdb-8eea-e1dfb07641b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Texto Inicial:\n",
            "\n",
            "<!DOCTYPE html>\n",
            "<html>\n",
            "<head>\n",
            "    <title>Example Title</title>\n",
            "</head>\n",
            "<body>\n",
            "    <p>This is an example paragraph. It contains some text! Text preprocessing is crucial for natural language processing (NLP).</p>\n",
            "    <p>Considerations for cleaning text data include removing HTML tags, punctuation, and stop words. Additionally, you might perform stemming and lemmatization.</p>\n",
            "</body>\n",
            "</html>\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Transformação em Minúsculas\n",
        "text = text.lower()\n",
        "print(\"\\nTexto em Minúsculas:\")\n",
        "print(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_GG-WoyNRl43",
        "outputId": "3980d99e-a994-44aa-d793-0ea3f48e46dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Texto em Minúsculas:\n",
            "\n",
            "<!doctype html>\n",
            "<html>\n",
            "<head>\n",
            "    <title>example title</title>\n",
            "</head>\n",
            "<body>\n",
            "    <p>this is an example paragraph. it contains some text! text preprocessing is crucial for natural language processing (nlp).</p>\n",
            "    <p>considerations for cleaning text data include removing html tags, punctuation, and stop words. additionally, you might perform stemming and lemmatization.</p>\n",
            "</body>\n",
            "</html>\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Remoção de Espaços em Branco\n",
        "text = text.strip()\n",
        "print(\"\\nTexto com Espaços em Branco Removidos:\")\n",
        "print(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8DEHwG_dRsO7",
        "outputId": "82385e9e-63f8-4eee-bf9b-003608d9bee2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Texto com Espaços em Branco Removidos:\n",
            "<!doctype html>\n",
            "<html>\n",
            "<head>\n",
            "    <title>example title</title>\n",
            "</head>\n",
            "<body>\n",
            "    <p>this is an example paragraph. it contains some text! text preprocessing is crucial for natural language processing (nlp).</p>\n",
            "    <p>considerations for cleaning text data include removing html tags, punctuation, and stop words. additionally, you might perform stemming and lemmatization.</p>\n",
            "</body>\n",
            "</html>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Remoção de Tags HTML\n",
        "text = BeautifulSoup(text, \"html.parser\").text\n",
        "print(\"\\nTexto sem Tags HTML:\")\n",
        "print(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tAz9E5IGRuhS",
        "outputId": "c674aa59-c5d1-4945-8f8a-e601b456844f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Texto sem Tags HTML:\n",
            "\n",
            "\n",
            "\n",
            "example title\n",
            "\n",
            "\n",
            "this is an example paragraph. it contains some text! text preprocessing is crucial for natural language processing (nlp).\n",
            "considerations for cleaning text data include removing html tags, punctuation, and stop words. additionally, you might perform stemming and lemmatization.\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Remoção de Pontuação\n",
        "text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "print(\"\\nTexto sem Pontuação:\")\n",
        "print(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9jXTDw7FRwEQ",
        "outputId": "d8c64d4c-b389-4d18-b1e0-128b9139bbd0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Texto sem Pontuação:\n",
            "\n",
            "\n",
            "\n",
            "example title\n",
            "\n",
            "\n",
            "this is an example paragraph it contains some text text preprocessing is crucial for natural language processing nlp\n",
            "considerations for cleaning text data include removing html tags punctuation and stop words additionally you might perform stemming and lemmatization\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Remoção de Espaços Extras\n",
        "text = re.sub(' +', ' ', text)\n",
        "print(\"\\nTexto com Espaços Extras Removidos:\")\n",
        "print(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V6YzDPYWRxz_",
        "outputId": "32ea541f-3874-44b3-d455-048fe176bbfd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Texto com Espaços Extras Removidos:\n",
            "\n",
            "\n",
            "\n",
            "example title\n",
            "\n",
            "\n",
            "this is an example paragraph it contains some text text preprocessing is crucial for natural language processing nlp\n",
            "considerations for cleaning text data include removing html tags punctuation and stop words additionally you might perform stemming and lemmatization\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenização e Remoção de Stop Words\n",
        "tokens = word_tokenize(text)\n",
        "stop_words = set(stopwords.words('english'))\n",
        "filtered_tokens = [word for word in tokens if word not in stop_words]\n",
        "print(\"\\nTokens Após Remoção de Stop Words:\")\n",
        "print(filtered_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rOcww9xIRzYd",
        "outputId": "a12e7788-e69d-4f30-946a-8d33a090ba31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Tokens Após Remoção de Stop Words:\n",
            "['example', 'title', 'example', 'paragraph', 'contains', 'text', 'text', 'preprocessing', 'crucial', 'natural', 'language', 'processing', 'nlp', 'considerations', 'cleaning', 'text', 'data', 'include', 'removing', 'html', 'tags', 'punctuation', 'stop', 'words', 'additionally', 'might', 'perform', 'stemming', 'lemmatization']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Stemming\n",
        "stemmer = PorterStemmer()\n",
        "stemmed_tokens = [stemmer.stem(word) for word in filtered_tokens]\n",
        "print(\"\\nTokens Após Stemming:\")\n",
        "print(stemmed_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cTBPn9aZR1LI",
        "outputId": "5c530d71-4b9a-4ad1-9bc4-063f4909c492"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Tokens Após Stemming:\n",
            "['exampl', 'titl', 'exampl', 'paragraph', 'contain', 'text', 'text', 'preprocess', 'crucial', 'natur', 'languag', 'process', 'nlp', 'consider', 'clean', 'text', 'data', 'includ', 'remov', 'html', 'tag', 'punctuat', 'stop', 'word', 'addit', 'might', 'perform', 'stem', 'lemmat']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Lematização\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "lemmatized_tokens = [lemmatizer.lemmatize(word) for word in filtered_tokens]\n",
        "print(\"\\nTokens Após Lematização:\")\n",
        "print(lemmatized_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EKGYNwGxR22M",
        "outputId": "26f84113-98e0-4850-efce-f55cbdd6efdd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Tokens Após Lematização:\n",
            "['example', 'title', 'example', 'paragraph', 'contains', 'text', 'text', 'preprocessing', 'crucial', 'natural', 'language', 'processing', 'nlp', 'consideration', 'cleaning', 'text', 'data', 'include', 'removing', 'html', 'tag', 'punctuation', 'stop', 'word', 'additionally', 'might', 'perform', 'stemming', 'lemmatization']\n"
          ]
        }
      ]
    }
  ]
}